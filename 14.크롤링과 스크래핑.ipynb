{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6ad3cb",
   "metadata": {},
   "source": [
    "# 데이터 다운로드 하기\n",
    ": 인터넷에서 지정된 파일을 내 PC에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6738f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "import urllib.request\n",
    "\n",
    "# URL과 저장 경로 지정\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"./Data/test.png\"\n",
    "\n",
    "# 다운로드 하기\n",
    "urllib.request.urlretrieve(url, savename) # (주소, 저장경로)\n",
    "print(\"저장 되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6231b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "import urllib.request\n",
    "\n",
    "# URL과 저장 경로 지정\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"./Data/test1.png\"\n",
    "\n",
    "# 다운로드 하기\n",
    "mem = urllib.request.urlopen(url).read()\n",
    "\n",
    "# 파일로 저장하기\n",
    "with open(savename, \"wb\") as f: # 이미지파일 wb, 텍스트파일 w\n",
    "    f.write(mem)\n",
    "print(\"저장되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fed32e",
   "metadata": {},
   "source": [
    "# BeautifulSoup로 Scraping하기\n",
    ": 간단하게 HTML과 XML에서 정보를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1294de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/tj/opt/anaconda3/lib/python3.8/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/tj/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 # 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b55c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html>\n",
      "<body>\n",
      "<h1>Header</h1>\n",
      "<p> Line 1을 서술 </p>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 기본 사용법\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML Sample\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <h1>Header</h1>\n",
    "            <p> Line 1을 서술 </p>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML분석\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e4c893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Header</h1>\n",
      "<p> Line 1을 서술 </p>\n",
      "-----------\n",
      "h1= Header\n",
      "h1= Header\n",
      "p1=  Line 1을 서술 \n",
      "p1=  Line 1을 서술 \n"
     ]
    }
   ],
   "source": [
    "# 원하는 부분 추출하기\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "print(h1)\n",
    "print(p1)\n",
    "print(\"-----------\")\n",
    "\n",
    "# Text만 출력\n",
    "print(\"h1=\", h1.string)\n",
    "print(\"h1=\", h1.text)\n",
    "print(\"p1=\", p1.string)\n",
    "print(\"p1=\", p1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ed9834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\"> Header </h1>\n",
      "<p id=\"body\"> Line 1을 서술 </p>\n",
      "title =   Header \n",
      "body =   Line 1을 서술 \n"
     ]
    }
   ],
   "source": [
    "# id로 요소를 추출하기\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML Sample\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <h1 id=\"title\"> Header </h1>\n",
    "            <p id=\"body\"> Line 1을 서술 </p>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 원하는 부분 추출하기(find는 맨 처음 1개의 요소만 가져옴)\n",
    "title = soup.find(id = \"title\")\n",
    "body = soup.find(id = 'body')\n",
    "print(title)\n",
    "print(body)\n",
    "\n",
    "# text만 출력\n",
    "print(\"title = \", title.string)\n",
    "print(\"body = \", body.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73c35a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.naver.com\">naver</a>,\n",
       " <a href=\"http://www.daum.net\">daum</a>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 개의 요소 추출하기\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML Sample\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <ul>\n",
    "                <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "                <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "            </ul>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 조건에 해당하는 걸 전부 가져오기(단순 text형태)\n",
    "links = soup.find_all('a')\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21f635c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver >>>> http://www.naver.com\n",
      "daum >>>> http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "# 원하는 부분 전부 추출하기\n",
    "for link in links:\n",
    "    #print(link.string) # 내용 가져오기\n",
    "    #print(link.attrs['href']) # 링크 가져오기(하이퍼링크 포함)\n",
    "    \n",
    "    href = link.attrs['href'] # 링크 가져오기(하이퍼링크 포함)\n",
    "    text = link.string # 내용 가져오기\n",
    "    print(text, \">>>>\", href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "243ade21",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-69b0aa81b11d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-69b0aa81b11d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    http://www.weather.go.kr/weather/forecast/mid-term-rss.jsp?stnld=109\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "http://www.weather.go.kr/weather/forecast/mid-term-rss.jsp?stnld=109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdcfaa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n",
      "--------------------\n",
      "<class 'list'>\n",
      "['○ (강수) 16일(금)~17일(토)에는 전국(수도권은 16일, 강원영동 제외)에 소나기가 오는 곳이 있겠습니다.', '          18일(일) 오전에 제주도에 비가 시작되어 18일(일) 오후에 충청권과 남부지방으로 확대되겠고, 19일(월) 오후에는 전국에 비가 오겠습니다.', '○ (기온) 이번 예보기간 아침 기온은 23~26도, 낮 기온은 29~34도로 어제(12일, 아침최저기온 23~26도, 낮최고기온 30~34도)와 비슷하겠습니다.', '○ (주말전망) 17일(토) 오후에 강원영서와 충청권, 남부지방, 제주도에 소나기가 오는 곳이 있겠습니다.', '              18일(일) 오전에 제주도에 비가 시작되어, 오후에는 충청권과 남부지방으로 확대되겠습니다. 아침 기온은 23~25도, 낮 기온은 29~33도가 되겠습니다.', ' * 이번 예보기간 동안 내륙을 중심으로 낮최고기온이 33도 이상, 아침최저기온이 25도 이상으로 올라 매우 무덥겠으니, 건강관리에 각별히 유의하기 바랍니다.', ' * 또한, 북태평양고기압 위치에 따라서 강수 변동성이 크겠으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.']\n",
      "--------------------\n",
      "○ (강수) 16일(금)~17일(토)에는 전국(수도권은 16일, 강원영동 제외)에 소나기가 오는 곳이 있겠습니다.\n",
      "18일(일) 오전에 제주도에 비가 시작되어 18일(일) 오후에 충청권과 남부지방으로 확대되겠고, 19일(월) 오후에는 전국에 비가 오겠습니다.\n",
      "○ (기온) 이번 예보기간 아침 기온은 23~26도, 낮 기온은 29~34도로 어제(12일, 아침최저기온 23~26도, 낮최고기온 30~34도)와 비슷하겠습니다.\n",
      "○ (주말전망) 17일(토) 오후에 강원영서와 충청권, 남부지방, 제주도에 소나기가 오는 곳이 있겠습니다.\n",
      "18일(일) 오전에 제주도에 비가 시작되어, 오후에는 충청권과 남부지방으로 확대되겠습니다. 아침 기온은 23~25도, 낮 기온은 29~33도가 되겠습니다.\n",
      "* 이번 예보기간 동안 내륙을 중심으로 낮최고기온이 33도 이상, 아침최저기온이 25도 이상으로 올라 매우 무덥겠으니, 건강관리에 각별히 유의하기 바랍니다.\n",
      "* 또한, 북태평양고기압 위치에 따라서 강수 변동성이 크겠으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "# 기상청 자료 활용하기\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"http://www.weather.go.kr/weather/forecast/mid-term-rss.jsp?stnld=109\"\n",
    "\n",
    "# data 가져오기\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# print(soup) - 확인용\n",
    "\n",
    "# 원하는 데이터 추출하기\n",
    "title = soup.find('title').string\n",
    "print(title) # 결과는 기상청 육상 중기예보\n",
    "wf = soup.find('wf').string # wf 태그에 해당하는 내용을 string 자료형으로 가져오기\n",
    "#print(wf) # 결과는 bs4.element.CData\n",
    "\n",
    "\n",
    "# '<br />'을 제외한 리스트 만들기\n",
    "listwf = wf.split('<br />')\n",
    "listwf?\n",
    "print('-'*20)\n",
    "print(type(listwf))\n",
    "print(listwf)\n",
    "print('-'*20)\n",
    "for i in listwf:\n",
    "    print(i.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79f9880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "○ (강수) 16일(금)~17일(토)에는 전국(수도권은 16일, 강원영동 제외)에 소나기가 오는 곳이 있겠습니다.           18일(일) 오전에 제주도에 비가 시작되어 18일(일) 오후에 충청권과 남부지방으로 확대되겠고, 19일(월) 오후에는 전국에 비가 오겠습니다. ○ (기온) 이번 예보기간 아침 기온은 23~26도, 낮 기온은 29~34도로 어제(12일, 아침최저기온 23~26도, 낮최고기온 30~34도)와 비슷하겠습니다. ○ (주말전망) 17일(토) 오후에 강원영서와 충청권, 남부지방, 제주도에 소나기가 오는 곳이 있겠습니다.               18일(일) 오전에 제주도에 비가 시작되어, 오후에는 충청권과 남부지방으로 확대되겠습니다. 아침 기온은 23~25도, 낮 기온은 29~33도가 되겠습니다.  * 이번 예보기간 동안 내륙을 중심으로 낮최고기온이 33도 이상, 아침최저기온이 25도 이상으로 올라 매우 무덥겠으니, 건강관리에 각별히 유의하기 바랍니다.  * 또한, 북태평양고기압 위치에 따라서 강수 변동성이 크겠으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' (강수) 16일(금)~17일(토)에는 전국(수도권은 16일, 강원영동 제외)에 소나기가 오는 곳이 있겠습니다.           18일(일) 오전에 제주도에 비가 시작되어 18일(일) 오후에 충청권과 남부지방으로 확대되겠고, 19일(월) 오후에는 전국에 비가 오겠습니다. ',\n",
       " ' (기온) 이번 예보기간 아침 기온은 23~26도, 낮 기온은 29~34도로 어제(12일, 아침최저기온 23~26도, 낮최고기온 30~34도)와 비슷하겠습니다. ',\n",
       " ' (주말전망) 17일(토) 오후에 강원영서와 충청권, 남부지방, 제주도에 소나기가 오는 곳이 있겠습니다.               18일(일) 오전에 제주도에 비가 시작되어, 오후에는 충청권과 남부지방으로 확대되겠습니다. 아침 기온은 23~25도, 낮 기온은 29~33도가 되겠습니다.  * 이번 예보기간 동안 내륙을 중심으로 낮최고기온이 33도 이상, 아침최저기온이 25도 이상으로 올라 매우 무덥겠으니, 건강관리에 각별히 유의하기 바랍니다.  * 또한, 북태평양고기압 위치에 따라서 강수 변동성이 크겠으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 정리하기\n",
    "list_wfs = list(wf)\n",
    "except_char = ['<','b','r','/','>']\n",
    "result = \"\"\n",
    "\n",
    "for lwf in list_wfs:\n",
    "    #print(lwf)\n",
    "    if lwf not in except_char:\n",
    "        result += lwf\n",
    "        \n",
    "print('-' * 100)\n",
    "print(result) # 자료형 str\n",
    "print(type(result))\n",
    "result.split('○') # 자료형 list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d2816",
   "metadata": {},
   "source": [
    "# css 선택자 사용하기\n",
    "\n",
    "soup.select_one() : css 선택자로 요소 하나를 추출.   \n",
    "soup.select() : css 선택자로 요소 여러 개를 리스트로 추출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61d30dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>위키 북스</h1>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <div id = 'meigen'>\n",
    "                <h1>위키 북스</h1>\n",
    "                <ul class=\"items\">\n",
    "                    <li>유니티 게임 이펙트 입문서</li>\n",
    "                    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "                    <li>모던 웹사이트 디자인의 정석</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 필요한 부분 css로 추출하기\n",
    "# 타이틀 부분 추출하기\n",
    "\n",
    "# id = 'meigen'의 자손 h1을 찾기\n",
    "h1 = soup.select_one(\"div#meigen > h1\") \n",
    "\n",
    "# ---정의---\n",
    "# id:#\n",
    "# class:.\n",
    "# > :자손\n",
    "# \"  \" : 후손\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cdfb879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>유니티 게임 이펙트 입문서</li>, <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>, <li>모던 웹사이트 디자인의 정석</li>]\n"
     ]
    }
   ],
   "source": [
    "# 목록 부분 추출하기\n",
    "li_lists = soup.select(\"div#meigen > ul.items > li\")\n",
    "print(li_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47636640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니티 게임 이펙트 입문서\n",
      "스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "# 목록 부분 텍스트만 추출하기\n",
    "for li in li_lists:\n",
    "    print(li.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 금융에서 환율 정보 추출하기\n",
    "# https://finance.naver.com/marketindex/\n",
    "\n",
    "# 개발자 도구 - Copy Selector\n",
    "# #exchangeList > li.on > a.head.usd > div > span.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e29dfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd /krw :  1,143.50\n"
     ]
    }
   ],
   "source": [
    "# 미국 환율 가져오기\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# HTML\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 데이터 추출하기\n",
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd /krw : \", price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "089f8ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"value\">1,144.00</span>, <span class=\"value\">1,036.42</span>, <span class=\"value\">1,358.16</span>, <span class=\"value\">176.85</span>, <span class=\"value\">110.2700</span>, <span class=\"value\">1.1867</span>, <span class=\"value\">1.3894</span>, <span class=\"value\">92.2500</span>, <span class=\"value\">74.1</span>, <span class=\"value\">1626.84</span>, <span class=\"value\">1805.5</span>, <span class=\"value\">66549.47</span>]\n"
     ]
    }
   ],
   "source": [
    "# 미국, 일본, 유럽연합, 중국의 환율\n",
    "# HTML\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 데이터 추출하기\n",
    "price_list = soup.select(\"div.head_info > span.value\")\n",
    "print(price_list) # list 내역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "90e6fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,144.00\n",
      "1,036.42\n",
      "1,358.16\n",
      "176.85\n",
      "110.2700\n",
      "1.1867\n",
      "1.3894\n",
      "92.2500\n",
      "74.1\n",
      "1626.84\n",
      "1805.5\n",
      "66549.47\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 text로 추출\n",
    "for price in price_list:\n",
    "    print(price.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "21f1d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 :  1,144.00\n",
      "일본 :  1,036.42\n",
      "유럽연합 :  1,358.16\n",
      "중국 :  176.85\n"
     ]
    }
   ],
   "source": [
    "# 정리\n",
    "print(\"미국 : \", price_list[0].string)\n",
    "print(\"일본 : \", price_list[1].string)\n",
    "print(\"유럽연합 : \", price_list[2].string)\n",
    "print(\"중국 : \", price_list[3].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ed41e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "<class 'list'>\n",
      "하늘과 바람과 별과 시\n",
      "서시\n",
      "자화상\n",
      "소년\n",
      "눈 오는 지도\n",
      "돌아와 보는 밤\n",
      "병원\n",
      "새로운 길\n",
      "간판 없는 거리\n",
      "태초의 아침\n",
      "또 태초의 아침\n",
      "새벽이 올 때까지\n",
      "무서운 시간\n",
      "십자가\n",
      "바람이 불어\n",
      "슬픈 족속\n",
      "눈감고 간다\n",
      "또 다른 고향\n",
      "길\n",
      "별 헤는 밤\n",
      "흰 그림자\n",
      "사랑스런 추억\n",
      "흐르는 거리\n",
      "쉽게 씌어진 시\n",
      "봄\n",
      "참회록\n",
      "간(肝)\n",
      "위로\n",
      "팔복\n",
      "못자는밤\n",
      "달같이\n",
      "고추밭\n",
      "아우의 인상화\n",
      "사랑의 전당\n",
      "이적\n",
      "비오는 밤\n",
      "산골물\n",
      "유언\n",
      "창\n",
      "바다\n",
      "비로봉\n",
      "산협의 오후\n",
      "명상\n",
      "소낙비\n",
      "한난계\n",
      "풍경\n",
      "달밤\n",
      "장\n",
      "밤\n",
      "황혼이 바다가 되어\n",
      "아침\n",
      "빨래\n",
      "꿈은 깨어지고\n",
      "산림\n",
      "이런날\n",
      "산상\n",
      "양지쪽\n",
      "닭\n",
      "가슴 1\n",
      "가슴 2\n",
      "비둘기\n",
      "황혼\n",
      "남쪽 하늘\n",
      "창공\n",
      "거리에서\n",
      "삶과 죽음\n",
      "초한대\n",
      "산울림\n",
      "해바라기 얼굴\n",
      "귀뚜라미와 나와\n",
      "애기의 새벽\n",
      "햇빛·바람\n",
      "반디불\n",
      "둘 다\n",
      "거짓부리\n",
      "눈\n",
      "참새\n",
      "버선본\n",
      "편지\n",
      "봄\n",
      "무얼 먹구 사나\n",
      "굴뚝\n",
      "햇비\n",
      "빗자루\n",
      "기왓장 내외\n",
      "오줌싸개 지도\n",
      "병아리\n",
      "조개껍질\n",
      "겨울\n",
      "트루게네프의 언덕\n",
      "달을 쏘다\n",
      "별똥 떨어진 데\n",
      "화원에 꽃이 핀다\n",
      "종시\n"
     ]
    }
   ],
   "source": [
    "# 윤동주 시안 작품 가져오기\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 작품 가져오기\n",
    "# 자료형 ResultSet\n",
    "title1 = soup.select(\"#mw-content-text > div.mw-parser-output > ul li a[title]\")\n",
    "# '>'가 없으면 그 밑의 모든 요소들을 가지고 옴\n",
    "print(type(title1))\n",
    "\n",
    "# 자료형 List\n",
    "title_list1 = list(title1)\n",
    "print(type(title_list1))\n",
    "\n",
    "\n",
    "for i in title1:\n",
    "    if i.string not in '증보판':\n",
    "        print(i.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b725043a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 하늘과 바람과 별과 시\n",
      "- 서시\n",
      "- 자화상\n",
      "- 소년\n",
      "- 눈 오는 지도\n",
      "- 돌아와 보는 밤\n",
      "- 병원\n",
      "- 새로운 길\n",
      "- 간판 없는 거리\n",
      "- 태초의 아침\n",
      "- 또 태초의 아침\n",
      "- 새벽이 올 때까지\n",
      "- 무서운 시간\n",
      "- 십자가\n",
      "- 바람이 불어\n",
      "- 슬픈 족속\n",
      "- 눈감고 간다\n",
      "- 또 다른 고향\n",
      "- 길\n",
      "- 별 헤는 밤\n",
      "- 흰 그림자\n",
      "- 사랑스런 추억\n",
      "- 흐르는 거리\n",
      "- 쉽게 씌어진 시\n",
      "- 봄\n",
      "- 참회록\n",
      "- 간(肝)\n",
      "- 위로\n",
      "- 팔복\n",
      "- 못자는밤\n",
      "- 달같이\n",
      "- 고추밭\n",
      "- 아우의 인상화\n",
      "- 사랑의 전당\n",
      "- 이적\n",
      "- 비오는 밤\n",
      "- 산골물\n",
      "- 유언\n",
      "- 창\n",
      "- 바다\n",
      "- 비로봉\n",
      "- 산협의 오후\n",
      "- 명상\n",
      "- 소낙비\n",
      "- 한난계\n",
      "- 풍경\n",
      "- 달밤\n",
      "- 장\n",
      "- 밤\n",
      "- 황혼이 바다가 되어\n",
      "- 아침\n",
      "- 빨래\n",
      "- 꿈은 깨어지고\n",
      "- 산림\n",
      "- 이런날\n",
      "- 산상\n",
      "- 양지쪽\n",
      "- 닭\n",
      "- 가슴 1\n",
      "- 가슴 2\n",
      "- 비둘기\n",
      "- 황혼\n",
      "- 남쪽 하늘\n",
      "- 창공\n",
      "- 거리에서\n",
      "- 삶과 죽음\n",
      "- 초한대\n",
      "- 산울림\n",
      "- 해바라기 얼굴\n",
      "- 귀뚜라미와 나와\n",
      "- 애기의 새벽\n",
      "- 햇빛·바람\n",
      "- 반디불\n",
      "- 둘 다\n",
      "- 거짓부리\n",
      "- 눈\n",
      "- 참새\n",
      "- 버선본\n",
      "- 편지\n",
      "- 봄\n",
      "- 무얼 먹구 사나\n",
      "- 굴뚝\n",
      "- 햇비\n",
      "- 빗자루\n",
      "- 기왓장 내외\n",
      "- 오줌싸개 지도\n",
      "- 병아리\n",
      "- 조개껍질\n",
      "- 겨울\n",
      "- 트루게네프의 언덕\n",
      "- 달을 쏘다\n",
      "- 별똥 떨어진 데\n",
      "- 화원에 꽃이 핀다\n",
      "- 종시\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# 윤동주 시안 작품 가져오기\n",
    "# #mw-content-text > div.mw-parser-output > ul:nth-child(6) > li > a\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 작품 가져오기\n",
    "a_list = soup.select(\"#mw-content-text > div.mw-parser-output > ul > li a\")\n",
    "\n",
    "for a in a_list:\n",
    "    if a.string == '증보판':\n",
    "        continue # 다시 for a in a_list: 로 올라가서 실행\n",
    "    print(\"-\", a.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48541e",
   "metadata": {},
   "source": [
    "## 다음 영화 연간 순위 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f1e49867",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 남산의 부장들\n",
      "2 : 다만 악에서 구하소서\n",
      "3 : 반도\n",
      "4 : 히트맨\n",
      "5 : 테넷\n",
      "6 : 백두산\n",
      "7 : #살아있다\n",
      "8 : 강철비2: 정상회담\n",
      "9 : 담보\n",
      "10 : 닥터 두리틀\n",
      "11 : 삼진그룹 영어토익반\n",
      "12 : 정직한 후보\n",
      "13 : 도굴\n",
      "14 : 클로젯\n",
      "15 : 오케이 마담\n",
      "16 : 해치지않아\n",
      "17 : 천문: 하늘에 묻는다\n",
      "18 : 결백\n",
      "19 : 1917\n",
      "20 : 작은 아씨들\n",
      "21 : 미드웨이\n",
      "22 : 시동\n",
      "23 : 지푸라기라도 잡고 싶은 짐승들\n",
      "24 : 미스터 주: 사라진 VIP\n",
      "25 : 인비저블맨\n",
      "26 : 나쁜 녀석들: 포에버\n",
      "27 : 국제수사\n",
      "28 : 침입자\n",
      "29 : 스타워즈: 라이즈 오브 스카이워커\n",
      "30 : 스파이 지니어스 \n",
      "31 : 이웃사촌\n",
      "32 : 온워드: 단 하루의 기적\n",
      "33 : 소리도 없이\n",
      "34 : 버즈 오브 프레이(할리 퀸의 황홀한 해방)\n",
      "35 : 원더 우먼 1984\n",
      "36 : 겨울왕국 2\n",
      "37 : 오! 문희\n",
      "38 : 그린랜드\n",
      "39 : 위대한 쇼맨\n",
      "40 : 런\n",
      "41 : 뮬란\n",
      "42 : 내가 죽던 날\n",
      "43 : 기생충\n",
      "44 : 신비아파트 극장판 하늘도깨비 대 요르문간드\n",
      "45 : 프리즌 이스케이프\n",
      "46 : 검객\n",
      "47 : 조제\n",
      "48 : 사라진 시간\n",
      "49 : 밤쉘: 세상을 바꾼 폭탄선언\n",
      "50 : 알라딘\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"https://movie.daum.net/ranking/boxoffice/yearly\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 영화 가져오기\n",
    "# #mainContent > div > div.box_boxoffice > ol > li:nth-child(1) > div > div.thumb_cont > strong > a\n",
    "\n",
    "movie_list = soup.select(\"strong a\")\n",
    "#print(movie_list)\n",
    "\n",
    "num = 1\n",
    "\n",
    "for movie in movie_list:\n",
    "    print(num, \":\", movie.string)\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183281b",
   "metadata": {},
   "source": [
    "## 많이 본 뉴스 가져오기\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f91dbd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713140143407\" data-tiara-id=\"20210713140143407\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"1\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713140143407\">\n",
      "                                        이재명, 긴급 기자회견..\"4차 팬데믹 못막으면 전면봉쇄 불가피\"\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713144711324\" data-tiara-id=\"20210713144711324\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"2\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713144711324\">\n",
      "                                        \"일출 보려다 물어뜯길 뻔\"..성산일출봉까지 점령한 야생들개\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713124446148\" data-tiara-id=\"20210713124446148\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"3\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713124446148\">\n",
      "                                        \"누나가 무슨 부모야\" 친누나 30차례 찔러 살해한 남동생.. 무기징역 구형\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713132549158\" data-tiara-id=\"20210713132549158\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"4\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713132549158\">\n",
      "                                        BJ철구, 7살딸과 '여캠BJ 새엄마 월드컵'..아동학대 논란\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713144622300\" data-tiara-id=\"20210713144622300\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"5\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713144622300\">\n",
      "                                        \"확진자인데 와서 미안\" 농담에 카페 영업중단..업무방해 무죄\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713133842565\" data-tiara-id=\"20210713133842565\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"6\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713133842565\">\n",
      "                                        정은경 '靑 방역기획관에 밀렸나' 질문에 \"소신껏 하고 있다\" 일축\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713114057051\" data-tiara-id=\"20210713114057051\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"7\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713114057051\">\n",
      "                                        \"술집 못가니 호텔 가자\" 60대 유명화가, 20대 성폭행 의혹\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713150601168\" data-tiara-id=\"20210713150601168\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"8\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713150601168\">\n",
      "                                        \"철학 붕괴\" 윤희숙 연일 이준석 비판..하태경 \"자해정치\"\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713135902248\" data-tiara-id=\"20210713135902248\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"9\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713135902248\">\n",
      "                                        \"이 시국에 떼창?\" 팬들 반발에..백기 든 '미스터트롯' 공연\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713113441712\" data-tiara-id=\"20210713113441712\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"10\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713113441712\">\n",
      "                                         우리은행 본점서 코로나19 집단감염..\"발설 시 엄벌\"\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713144944406\" data-tiara-id=\"20210713144944406\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"11\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713144944406\">\n",
      "                                        중등교원 양성 규모 축소..사범대 나와야 국영수 교사된다\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713115724852\" data-tiara-id=\"20210713115724852\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"12\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713115724852\">\n",
      "                                        \"한국인 DNA에 표현력 없다\" 바이올린 거장 주커만 인종차별\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713113230612\" data-tiara-id=\"20210713113230612\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"13\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713113230612\">\n",
      "                                        홍남기, 전국민 지원금 합의에 \"동의 안한다\"..여당과 충돌\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713143600846\" data-tiara-id=\"20210713143600846\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"14\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713143600846\">\n",
      "                                        청와대 앞에 착륙한 미끼 전투기, 힘을 보여주고 싶었다\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713125407426\" data-tiara-id=\"20210713125407426\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"15\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713125407426\">\n",
      "                                        짧고 굵은 장마 19일까지..20일부터 강한 폭염 온다\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713120602280\" data-tiara-id=\"20210713120602280\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"16\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713120602280\">\n",
      "                                        습도 높으면 35도서도 치명타..습한 한국 여름 무서운 이유\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713115624812\" data-tiara-id=\"20210713115624812\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"17\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713115624812\">\n",
      "                                        무려 60년간 조용하던 쿠바인들은 왜 들고 일어났나\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713131902974\" data-tiara-id=\"20210713131902974\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"18\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713131902974\">\n",
      "                                        \"돼지코 같다\" 싸늘한 반응..BMW 4시리즈 참혹한 결과\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713133106300\" data-tiara-id=\"20210713133106300\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"19\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713133106300\">\n",
      "                                         '천조국 최종병기' 대륙간탄도미사일 미니트맨 Ⅲ\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713151947679\" data-tiara-id=\"20210713151947679\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"20\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713151947679\">\n",
      "                                        전여옥, 위기의 이준석에 \"뒤에서 칼꽂는 게 정치..성인식 치러\"\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713133325380\" data-tiara-id=\"20210713133325380\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"21\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713133325380\">\n",
      "                                        예고 없이 잡힌 미스터트롯 전주 콘서트, 잇단 항의에 취소\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713141248818\" data-tiara-id=\"20210713141248818\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"22\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713141248818\">\n",
      "                                        \"제가 가르쳤고 믿고 있는..\" 조국, 아내 정경심 징역 7년 구형에 '무죄 추정' 대법 판결 공유\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713142508329\" data-tiara-id=\"20210713142508329\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"23\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713142508329\">\n",
      "                                        부산도 위태롭다..유흥시설 넘어 식당·학교 등 전방위 확산\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713131915980\" data-tiara-id=\"20210713131915980\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"24\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713131915980\">\n",
      "                                        \"4000모 이식한거 맞아?\"..모발 이식 사진은 의료기록인가, 아닌가\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713111827741\" data-tiara-id=\"20210713111827741\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"25\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713111827741\">\n",
      "                                        \"살려주세요\" 외침에 바로 '풍덩'..초등생 3명 잇따라 구한 40대\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713152355845\" data-tiara-id=\"20210713152355845\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"26\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713152355845\">\n",
      "                                        중국서 2명 살해한 50대 현지인..34년만에 인천서 검거\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713115700827\" data-tiara-id=\"20210713115700827\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"27\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713115700827\">\n",
      "                                        \"내년 하반기 미 금융시장 대폭락 온다\"\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713151603547\" data-tiara-id=\"20210713151603547\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"28\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713151603547\">\n",
      "                                        양어장을 탈출한 송어는 뇌가 커진다\n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713140105375\" data-tiara-id=\"20210713140105375\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"29\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713140105375\">\n",
      "                                        연인 관계 2/3, 친구서 발전 \n",
      "                                    </a>, <a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20210713132558167\" data-tiara-id=\"20210713132558167\" data-tiara-layer=\"RIGHT popular_news news_list\" data-tiara-ordnum=\"30\" data-tiara-type=\"harmony\" href=\"https://v.daum.net/v/20210713132558167\">\n",
      "                                        정은경, 55~59세 예약 중단에 \"안내 못드려 송구..충분히 접종 가능\"\n",
      "                                    </a>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"https://news.daum.net/digital\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTML 분석\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "#mAside > div.aside_g.aside_ranking > ul > li.on > div > ol:nth-child(4) > li:nth-child(10) > strong > a\n",
    "#mAside > div.aside_g.aside_ranking > ul > li.on > div > ol:nth-child(2) > li:nth-child(1) > strong\n",
    "popular_news_list = soup.select(\"#mAside > div.aside_g.aside_ranking > ul > li.on > div > ol > li > strong > a\")\n",
    "print(popular_news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05304f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d726f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05866a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb9117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b05e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
